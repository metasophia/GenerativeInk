<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>bayes on</title><link>/categories/bayes/</link><description>Recent content in bayes on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 06 Jul 2021 20:48:54 -0400</lastBuildDate><atom:link href="/categories/bayes/index.xml" rel="self" type="application/rss+xml"/><item><title>Quantifying curation</title><link>/posts/quantifying-curation/</link><pubDate>Tue, 06 Jul 2021 20:48:54 -0400</pubDate><guid>/posts/quantifying-curation/</guid><description>Updates
11/18/21: Added section on satisficing.
A human curator administers selection pressure to GPT-3&amp;rsquo;s outputs
Previously, I tagged content generated collaboratively with GPT-3 with a curation ratio, intended to give an approximate sense of the amount of cherrypicking involved in its creation. Others have similarly used a ratio to indicate curation selectivity. However, this description doesnâ€™t distinguish between, say, choosing the best of 5 entire essays generated by GPT-3 and choosing the best of 5 sentences every sentence.</description></item><item><title>Language models are 0-shot interpreters</title><link>/posts/language-models-are-0-shot-interpreters/</link><pubDate>Wed, 10 Feb 2021 17:59:55 -0500</pubDate><guid>/posts/language-models-are-0-shot-interpreters/</guid><description>! Correction: The logprobs returned by the OpenAI API use natural log, not base 10, so all occurences of decibels / dB in this post should actually say nats. I&amp;rsquo;ll either make that substitution at some point or convert everything to actual decibels.
Overview I present evidence that the efficacy of 0-shot prompts for GPT-3 has been underestimated, and that more powerful models are more effective at deriving information from 0-shot prompts, while less powerful models have greater need for examples on equivalent tasks.</description></item></channel></rss>