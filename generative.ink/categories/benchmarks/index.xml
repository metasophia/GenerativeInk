<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>benchmarks on</title><link>/categories/benchmarks/</link><description>Recent content in benchmarks on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 10 Feb 2021 17:59:55 -0500</lastBuildDate><atom:link href="/categories/benchmarks/index.xml" rel="self" type="application/rss+xml"/><item><title>Language models are 0-shot interpreters</title><link>/posts/language-models-are-0-shot-interpreters/</link><pubDate>Wed, 10 Feb 2021 17:59:55 -0500</pubDate><guid>/posts/language-models-are-0-shot-interpreters/</guid><description>! Correction: The logprobs returned by the OpenAI API use natural log, not base 10, so all occurences of decibels / dB in this post should actually say nats. I&amp;rsquo;ll either make that substitution at some point or convert everything to actual decibels.
Overview I present evidence that the efficacy of 0-shot prompts for GPT-3 has been underestimated, and that more powerful models are more effective at deriving information from 0-shot prompts, while less powerful models have greater need for examples on equivalent tasks.</description></item></channel></rss>