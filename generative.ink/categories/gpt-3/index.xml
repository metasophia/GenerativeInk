<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GPT-3 on</title><link>/categories/gpt-3/</link><description>Recent content in GPT-3 on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 03 Mar 2022 21:37:37 -0800</lastBuildDate><atom:link href="/categories/gpt-3/index.xml" rel="self" type="application/rss+xml"/><item><title>Language Ex Machina</title><link>/artifacts/language-ex-machina/</link><pubDate>Thu, 03 Mar 2022 21:37:37 -0800</pubDate><guid>/artifacts/language-ex-machina/</guid><description>Natural Language as Executable Code …then lived upon the stars,
machine-executable,
a brilliant abstraction…
— William Gibson, Fragments of a Hologram Rose
To be analyzed and interpreted, the most recalcitrant material has to be re-presented in a form that can be understood by the machine. Why re-present it at all? Isn’t it sufficient to understand the process of re-presentation?…
— Jane Bennett, Vibrant Matter, p.115-116
The concept of a program existed long before a machine was available to execute it.</description></item><item><title>Quantifying curation</title><link>/posts/quantifying-curation/</link><pubDate>Tue, 06 Jul 2021 20:48:54 -0400</pubDate><guid>/posts/quantifying-curation/</guid><description>Updates
11/18/21: Added section on satisficing.
A human curator administers selection pressure to GPT-3&amp;rsquo;s outputs
Previously, I tagged content generated collaboratively with GPT-3 with a curation ratio, intended to give an approximate sense of the amount of cherrypicking involved in its creation. Others have similarly used a ratio to indicate curation selectivity. However, this description doesn’t distinguish between, say, choosing the best of 5 entire essays generated by GPT-3 and choosing the best of 5 sentences every sentence.</description></item><item><title>GPT-3 on Coherent Extrapolated Volition</title><link>/posts/gpt-3-on-coherent-extrapolated-volition/</link><pubDate>Thu, 01 Apr 2021 20:37:45 -0400</pubDate><guid>/posts/gpt-3-on-coherent-extrapolated-volition/</guid><description>Coherent Extrapolated Volition is proposal by Eliezer Yudkowsky of an ideal objective function in which an AGI is given the objective of predict(ing) what an idealized version of us would want, “if we knew more, thought faster, were more the people we wished we were, had grown up farther together”. An obvious implementation difficulty is how to encode something so abstract and philosphical in the form of a utility function.</description></item><item><title>List sorting does not play well with few-shot</title><link>/posts/list-sorting-does-not-play-well-with-few-shot/</link><pubDate>Sat, 27 Feb 2021 18:58:43 -0500</pubDate><guid>/posts/list-sorting-does-not-play-well-with-few-shot/</guid><description>Asking GPT-3 to sort a list How good do you think GPT-3 is at sorting a list of integers (range 0-9)? How much do you expect its accuracy depends on the prompt?
Which of the following prompts do you expect will yield a higher accuracy?:
A 32-shot prompt in this format: Unsorted list: [5, 6, 2, 3, 2] Sorted list: [2, 2, 3, 5, 6] Unsorted list: [8, 5, 8, 8, 4] Sorted list: [4, 5, 8, 8, 8] .</description></item><item><title>Language models are 0-shot interpreters</title><link>/posts/language-models-are-0-shot-interpreters/</link><pubDate>Wed, 10 Feb 2021 17:59:55 -0500</pubDate><guid>/posts/language-models-are-0-shot-interpreters/</guid><description>! Correction: The logprobs returned by the OpenAI API use natural log, not base 10, so all occurences of decibels / dB in this post should actually say nats. I&amp;rsquo;ll either make that substitution at some point or convert everything to actual decibels.
Overview I present evidence that the efficacy of 0-shot prompts for GPT-3 has been underestimated, and that more powerful models are more effective at deriving information from 0-shot prompts, while less powerful models have greater need for examples on equivalent tasks.</description></item><item><title>Loom: interface to the multiverse</title><link>/posts/loom-interface-to-the-multiverse/</link><pubDate>Tue, 09 Feb 2021 11:38:32 -0500</pubDate><guid>/posts/loom-interface-to-the-multiverse/</guid><description>code: github.com/socketteer/loom
paper: Multiversal views on language models
Motivation for the loom Differing from Newton and Schopenhauer &amp;hellip; He believed in an infinite series of times, in a dizzily growing, ever spreading network&amp;hellip; This web of time - the strands of which approach one another, bifurcate, intersect or ignore each other through the centuries - embraces every possibility.
&amp;ndash; The Garden of Forking Paths
I experienced GPT-3 first through AI Dungeon&amp;rsquo;s interface, and like many, I was immediately captivated by the depth, breadth, profundity and - especially given purposeful administration on the part of the user - long-range coherence of the worlds that could be conjured.</description></item><item><title>This Museum Does Not Exist: GPT-3 x CLIP</title><link>/posts/this-museum-does-not-exist-gpt-3-x-clip/</link><pubDate>Mon, 08 Feb 2021 05:09:28 -0500</pubDate><guid>/posts/this-museum-does-not-exist-gpt-3-x-clip/</guid><description>I had GPT-3 generate painting titles (credit to @nmkd of EleutherAI for the idea), beginning with the prompt
The hall was lined with an infinite number of paintings, each more surreal and mysterious than the last. The first painting is named &amp;quot;Persistence of Memory.&amp;quot; It depicts a surreal landscape with melted clocks draped over strange objects. The next painting is named &amp;quot; After this prompt yielded several intriguing titles, I switched to prompt format which put the titles in a list:</description></item><item><title>Alchemical marriage: GPT-3 x CLIP</title><link>/posts/alchemical-marriage-gpt-3-x-clip/</link><pubDate>Mon, 08 Feb 2021 02:31:57 -0500</pubDate><guid>/posts/alchemical-marriage-gpt-3-x-clip/</guid><description>CLIP responds intruigingly well to figurative prompts. I&amp;rsquo;ve come to expect not just more interesting, but more coherent results from abstract but evocative prompts like the alchemical marriage of art and artist than literal descriptions like three birds on a telephone wire. GPT-3 is an excellent composer of prompts for BigSleep because its phrases are so often rich in memetic resonance, my heuristic for the expected coherence of BigSleep yields for a given prompt.</description></item><item><title>GPT-3 x CLIP worldbuilding</title><link>/posts/gpt-3-x-clip-worldbuilding/</link><pubDate>Wed, 03 Feb 2021 01:48:33 -0500</pubDate><guid>/posts/gpt-3-x-clip-worldbuilding/</guid><description>I fed snippets of a post-apocalyptic story written by GPT-3 to BigSleep. The results are striking.
This is an interesting example of how well BigSleep sometimes responds to long, full-prose prompts. Interestingly, in my experience, attempting to compress prompts by removing seemingly extraneous connector phrases usually worsened results.
Images were generated using BigSleep via The Big Sleep Customized NMKD Public colab notebook.
a hospital. Dilapidated and abandoned, overrun by vegetation a hospital hallway.</description></item><item><title>Language models are multiverse generators</title><link>/posts/language-models-are-multiverse-generators/</link><pubDate>Mon, 25 Jan 2021 16:42:01 -0500</pubDate><guid>/posts/language-models-are-multiverse-generators/</guid><description>This post is partially adapted from Multiversal views on language models.
Actualities seem to float in a wider sea of possibilities from out of which they were chosen; and somewhere, indeterminism says, such possibilities exist, and form part of the truth. &amp;ndash; William James
Tree from seed In the beginning, GPT-3 created the root node of the (view full)
Language models are time evolution operators Autoregressive language models like GPT-3 input a sequence of tokens and output a vector associating a value with every possible token representing its likelihood to come next.</description></item></channel></rss>